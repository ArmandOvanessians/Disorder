{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArmandOvanessians/Disorder/blob/main/Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D90giI_FR9C0",
        "outputId": "b9a1eace-4523-4684-8ea0-81dfc45e3f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torch-geometric networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6IlFKDnPhbh"
      },
      "outputs": [],
      "source": [
        "# System & Utility Imports\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import numpy\n",
        "# Math and Data Handling\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "# Machine Learning & Data Processing\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import shap\n",
        "# PyTorch and PyTorch Geometric\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "# NetworkX for Graph Handling\n",
        "import networkx as nx\n",
        "# Google Colab Specific Imports\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOATRhe4PvvR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaMaSNBkR1Vs",
        "outputId": "8376dd43-3107-496d-81a0-d494f670cb18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "The total amount of graphs: 332\n",
            "The total amount of graphs: 179\n",
            "The total amount of graphs: 2425\n"
          ]
        }
      ],
      "source": [
        "# Get access to the dataset and load it up\n",
        "drive.mount('/content/drive')\n",
        "graphs_K = '/content/drive/My Drive/Disorder/Input_data/graphs_Kaia.pkl' # includes mostly repressors\n",
        "graphs_S = '/content/drive/My Drive/Disorder/Input_data/graphs_STARK.pkl'\n",
        "graphs_B = '/content/drive/My Drive/Disorder/Input_data/graphs_BINTU.pkl'\n",
        "\n",
        "with open(graphs_K, 'rb') as f:\n",
        "    graphs_K = pickle.load(f)\n",
        "print(f\"The total amount of graphs: {len(graphs_K)}\")\n",
        "\n",
        "with open(graphs_S, 'rb') as f:\n",
        "    graphs_S = pickle.load(f)\n",
        "print(f\"The total amount of graphs: {len(graphs_S)}\")\n",
        "\n",
        "with open(graphs_B, 'rb') as f:\n",
        "    graphs_B = pickle.load(f)\n",
        "print(f\"The total amount of graphs: {len(graphs_B)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZlBZPW9qIFW"
      },
      "source": [
        "# Define Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT8-HWqYqE9P"
      },
      "outputs": [],
      "source": [
        "# Define model parameters\n",
        "num_features = graphs_K[0].num_node_features # features should be consistent across all graphs\n",
        "hidden_dim = 32    # You can adjust this\n",
        "out_dim = 16       # You can adjust this\n",
        "num_classes = len(set([graph.y.item() for graph in graphs_K]))  # Assuming y is a single value\n",
        "class_names = [f'Class {i}' for i in range(num_classes)]  # Adjust based on your classes\n",
        "\n",
        "# For M1H\n",
        "for graph in graphs_K:\n",
        "    if graph.y.item() == -1:\n",
        "        graph.y = torch.tensor([0])\n",
        "    elif graph.y.item() == 1:\n",
        "        graph.y = torch.tensor([1])\n",
        "\n",
        "# For M1H\n",
        "for graph in graphs_S:\n",
        "    if graph.y.item() == -1:\n",
        "        graph.y = torch.tensor([0])\n",
        "    elif graph.y.item() == 1:\n",
        "        graph.y = torch.tensor([1])\n",
        "\n",
        "# For M1H\n",
        "for graph in graphs_B:\n",
        "    if graph.y.item() == -1:\n",
        "        graph.y = torch.tensor([0])\n",
        "    elif graph.y.item() == 1:\n",
        "        graph.y = torch.tensor([1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVcNya4wl8z7"
      },
      "source": [
        "Graph Attention network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93hjQgDLlgmL"
      },
      "outputs": [],
      "source": [
        "class GATWithMasking(nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim, out_dim, num_classes, num_heads=4):\n",
        "        super(GATWithMasking, self).__init__()\n",
        "\n",
        "        # GATConv layers\n",
        "        self.conv1 = GATConv(num_features, hidden_dim // num_heads, heads=num_heads, concat=True)\n",
        "        self.conv2 = GATConv(hidden_dim, out_dim, heads=1, concat=False)  # Output one attention head for the final layer\n",
        "\n",
        "        # BatchNorm and Dropout\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)  # Add BatchNorm\n",
        "\n",
        "        self.bn2 = nn.BatchNorm1d(out_dim)\n",
        "        self.dropout = nn.Dropout(0.5)  # Add Dropout\n",
        "\n",
        "        # Fully connected layer for classification output\n",
        "        self.fc = nn.Linear(out_dim, num_classes)  # Output logits for num_classes\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # Create a mask where 1 = valid, 0 = NaN (or missing)\n",
        "        mask = ~torch.isnan(x)\n",
        "\n",
        "        # Replace NaNs with 0 for computation\n",
        "        x = torch.nan_to_num(x, nan=0.0)\n",
        "\n",
        "        # Apply GATConv layers with batch normalization and dropout\n",
        "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        x = self.bn2(self.conv2(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)  # Pooling over the nodes in the same graph\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through final fully connected layer to output logits for each class\n",
        "        x = self.fc(x)\n",
        "        return x  # Logits for each class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "\n",
        "class GAT_BINTU(nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim, out_dim, num_classes, num_heads=4):\n",
        "        super(GAT_BINTU, self).__init__()\n",
        "\n",
        "        # GATConv layers\n",
        "        self.conv1 = GATConv(num_features, hidden_dim // num_heads, heads=num_heads, concat=True)\n",
        "        self.conv2 = GATConv(hidden_dim, hidden_dim // num_heads, heads=num_heads, concat=True)  # Additional GAT layer\n",
        "        self.conv3 = GATConv(hidden_dim, out_dim, heads=1, concat=False)  # Final GAT layer with 1 head\n",
        "\n",
        "        # BatchNorm and Dropout\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.bn3 = nn.BatchNorm1d(out_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Fully connected layer for classification output\n",
        "        self.fc = nn.Linear(out_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # Create a mask where 1 = valid, 0 = NaN (or missing)\n",
        "        mask = ~torch.isnan(x)\n",
        "\n",
        "        # Replace NaNs with 0 for computation\n",
        "        x = torch.nan_to_num(x, nan=0.0)\n",
        "\n",
        "        # Apply GATConv layers with batch normalization and dropout\n",
        "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        x = F.relu(self.bn2(self.conv2(x, edge_index)))  # New GAT layer\n",
        "        x = self.bn3(self.conv3(x, edge_index))\n",
        "\n",
        "        # Pooling over the nodes in the same graph\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through final fully connected layer to output logits for each class\n",
        "        x = self.fc(x)\n",
        "        return x  # Logits for each class\n"
      ],
      "metadata": {
        "id": "cm6SMTpNUVoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT8TOwJOmBNd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "class WeightedCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, weight=None):\n",
        "        super(WeightedCrossEntropyLoss, self).__init__()\n",
        "        self.weight = weight\n",
        "        self.loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
        "\n",
        "    def forward(self, outputs, labels):\n",
        "        return self.loss_fn(outputs, labels)\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, weight=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, weight=self.weight, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(true_labels, predicted_labels, class_names, save_path=None):\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    # Plot the confusion matrix using seaborn\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "\n",
        "    # Save plot if save_path is provided\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        print(f'Saved confusion matrix plot to {save_path}')\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def cross_validate(\n",
        "    graphs, labels, num_features, hidden_dim, out_dim, num_classes, class_names,\n",
        "    k_folds=5, num_epochs=100, save_path='/content/drive/My Drive/Disorder/Models/model_test'\n",
        "):\n",
        "    # Create the save directory if it doesn't exist\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "\n",
        "    stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    #class_weights = torch.tensor([2.0, 1.0], dtype=torch.float32).to(device) # used for M1H data\n",
        "    class_weights = torch.tensor([1.0, 20], dtype=torch.float32).to(device) # used for Bintu Lab\n",
        "    fold_accuracies = []\n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    best_true_labels = []\n",
        "    best_predicted_labels = []\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(stratified_kfold.split(graphs, labels)):\n",
        "        print(f'\\nFold {fold + 1}/{k_folds}')\n",
        "\n",
        "        # Prepare training and test datasets\n",
        "        train_dataset = [graphs[i] for i in train_idx]\n",
        "        test_dataset = [graphs[i] for i in test_idx]\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = GATWithMasking(num_features, hidden_dim, out_dim, num_classes).to(device)\n",
        "        #model = GAT_BINTU(num_features, hidden_dim, out_dim, num_classes).to(device)\n",
        "\n",
        "        # Define optimizer and loss function\n",
        "        #optimizer = optim.Adam(model.parameters(), lr=0.01) # used for M1H data\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.01) # used for Bintu\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights) # used for M1H data\n",
        "        # Use FocalLoss instead of CrossEntropyLoss\n",
        "        #criterion = FocalLoss(gamma=2.0, weight=class_weights) # for BINTU\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "\n",
        "            for data in train_loader:\n",
        "                data = data.to(device)\n",
        "                data.y = data.y.long()\n",
        "                optimizer.zero_grad()\n",
        "                out = model(data)\n",
        "                loss = criterion(out, data.y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        true_labels = []\n",
        "        predicted_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                data = data.to(device)\n",
        "                data.y = data.y.long()\n",
        "                out = model(data)\n",
        "                preds = out.argmax(dim=1)\n",
        "                true_labels.extend(data.y.cpu().numpy())\n",
        "                predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "        # Calculate accuracy for the current fold\n",
        "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "        fold_accuracies.append(accuracy)\n",
        "        print(f'Fold {fold + 1} Accuracy: {accuracy:.4f}')\n",
        "\n",
        "        # Save the best model\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model.state_dict()\n",
        "            best_true_labels = true_labels\n",
        "            best_predicted_labels = predicted_labels\n",
        "\n",
        "    avg_accuracy = sum(fold_accuracies) / k_folds\n",
        "    print(f'\\nAverage Accuracy across all folds: {avg_accuracy:.4f}')\n",
        "\n",
        "    # Save the best model weights\n",
        "    model_save_path = os.path.join(save_path, 'best_gat_model.pth')\n",
        "    torch.save(best_model, model_save_path)\n",
        "    print(f'Saved best model weights to {model_save_path}')\n",
        "\n",
        "    # Save the true, predicted labels for the best model, save\n",
        "    true_labels_path = os.path.join(save_path, 'best_true_labels.npy')\n",
        "    predicted_labels_path = os.path.join(save_path, 'best_predicted_labels.npy')\n",
        "    confusion_path = os.path.join(save_path, 'confusion.png')\n",
        "\n",
        "\n",
        "    np.save(true_labels_path, best_true_labels)\n",
        "    np.save(predicted_labels_path, best_predicted_labels)\n",
        "\n",
        "    print(f'Saved true labels to {true_labels_path}')\n",
        "    print(f'Saved predicted labels to {predicted_labels_path}')\n",
        "\n",
        "    # Plot confusion matrix for the best model\n",
        "    #plot_confusion_matrix(best_true_labels, best_predicted_labels, class_names)\n",
        "    plot_confusion_matrix(best_true_labels, best_predicted_labels, class_names, save_path=confusion_path)\n",
        "\n",
        "\n",
        "    return fold_accuracies, best_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch_geometric.loader import DataLoader\n",
        "# from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "# def cross_validate_sampled(\n",
        "#     graphs, labels, num_features, hidden_dim, out_dim, num_classes, class_names,\n",
        "#     k_folds=5, num_epochs=100, save_path='/content/drive/My Drive/Disorder/Models/model_test'\n",
        "# ):\n",
        "#     # Create the save directory if it doesn't exist\n",
        "#     os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#     print(f'Using device: {device}')\n",
        "\n",
        "#     stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "#     class_weights = torch.tensor([1.0, 5], dtype=torch.float32).to(device)\n",
        "#     fold_accuracies = []\n",
        "#     best_model = None\n",
        "#     best_accuracy = 0.0\n",
        "#     best_true_labels = []\n",
        "#     best_predicted_labels = []\n",
        "\n",
        "#     for fold, (train_idx, test_idx) in enumerate(stratified_kfold.split(graphs, labels)):\n",
        "#         print(f'\\nFold {fold + 1}/{k_folds}')\n",
        "\n",
        "#         # Prepare training and test datasets\n",
        "#         train_dataset = [graphs[i] for i in train_idx]\n",
        "#         train_labels = [labels[i] for i in train_idx]\n",
        "#         test_dataset = [graphs[i] for i in test_idx]\n",
        "\n",
        "#         # Calculate class weights for oversampling\n",
        "#         class_counts = np.bincount(train_labels)\n",
        "#         sample_weights = [1.0 / class_counts[label] for label in train_labels]\n",
        "\n",
        "#         # Create a WeightedRandomSampler for oversampling Class 1\n",
        "#         sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "#         # Use PyTorch Geometric DataLoader with the sampler\n",
        "#         train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler)\n",
        "#         test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "#         # Initialize the model\n",
        "#         #model = GATWithMasking(num_features, hidden_dim, out_dim, num_classes).to(device)\n",
        "\n",
        "#         # Define optimizer and loss function\n",
        "#         optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "#         #criterion = FocalLoss(gamma=2.0, weight=class_weights)\n",
        "#         criterion = nn.CrossEntropyLoss(weight=class_weights) # used for M1H data\n",
        "\n",
        "#         # Training loop\n",
        "#         for epoch in range(num_epochs):\n",
        "#             model.train()\n",
        "#             total_loss = 0\n",
        "\n",
        "#             for data in train_loader:\n",
        "#                 data = data.to(device)\n",
        "#                 data.y = data.y.long()\n",
        "#                 optimizer.zero_grad()\n",
        "#                 out = model(data)\n",
        "#                 loss = criterion(out, data.y)\n",
        "#                 loss.backward()\n",
        "#                 optimizer.step()\n",
        "#                 total_loss += loss.item()\n",
        "\n",
        "#             avg_loss = total_loss / len(train_loader)\n",
        "#             print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "#         # Evaluation\n",
        "#         model.eval()\n",
        "#         true_labels = []\n",
        "#         predicted_labels = []\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for data in test_loader:\n",
        "#                 data = data.to(device)\n",
        "#                 data.y = data.y.long()\n",
        "#                 out = model(data)\n",
        "#                 preds = out.argmax(dim=1)\n",
        "#                 true_labels.extend(data.y.cpu().numpy())\n",
        "#                 predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "#         # Calculate accuracy for the current fold\n",
        "#         accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "#         fold_accuracies.append(accuracy)\n",
        "#         print(f'Fold {fold + 1} Accuracy: {accuracy:.4f}')\n",
        "\n",
        "#         # Save the best model\n",
        "#         if accuracy > best_accuracy:\n",
        "#             best_accuracy = accuracy\n",
        "#             best_model = model.state_dict()\n",
        "#             best_true_labels = true_labels\n",
        "#             best_predicted_labels = predicted_labels\n",
        "\n",
        "#     avg_accuracy = sum(fold_accuracies) / k_folds\n",
        "#     print(f'\\nAverage Accuracy across all folds: {avg_accuracy:.4f}')\n",
        "\n",
        "#     # Save the best model weights\n",
        "#     model_save_path = os.path.join(save_path, 'best_gat_model.pth')\n",
        "#     torch.save(best_model, model_save_path)\n",
        "#     print(f'Saved best model weights to {model_save_path}')\n",
        "\n",
        "#     # Save the true, predicted labels for the best model\n",
        "#     true_labels_path = os.path.join(save_path, 'best_true_labels.npy')\n",
        "#     predicted_labels_path = os.path.join(save_path, 'best_predicted_labels.npy')\n",
        "#     confusion_path = os.path.join(save_path, 'confusion.png')\n",
        "\n",
        "#     np.save(true_labels_path, best_true_labels)\n",
        "#     np.save(predicted_labels_path, best_predicted_labels)\n",
        "\n",
        "#     print(f'Saved true labels to {true_labels_path}')\n",
        "#     print(f'Saved predicted labels to {predicted_labels_path}')\n",
        "\n",
        "#     # Plot confusion matrix for the best model\n",
        "#     plot_confusion_matrix(best_true_labels, best_predicted_labels, class_names, save_path=confusion_path)\n",
        "\n",
        "#     return fold_accuracies, best_accuracy\n"
      ],
      "metadata": {
        "id": "gRy_oEm6wfhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkXhovRDk5FC",
        "outputId": "45de1d5a-1886-4094-b9a2-c4143464fae7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "\n",
            "Fold 1/5\n",
            "Epoch 1/50, Loss: 0.5171\n",
            "Epoch 2/50, Loss: 0.4668\n",
            "Epoch 3/50, Loss: 0.4175\n",
            "Epoch 4/50, Loss: 0.3979\n",
            "Epoch 5/50, Loss: 0.3646\n",
            "Epoch 6/50, Loss: 0.3581\n",
            "Epoch 7/50, Loss: 0.3553\n",
            "Epoch 8/50, Loss: 0.3316\n",
            "Epoch 9/50, Loss: 0.3329\n",
            "Epoch 10/50, Loss: 0.3498\n",
            "Epoch 11/50, Loss: 0.3412\n",
            "Epoch 12/50, Loss: 0.3277\n",
            "Epoch 13/50, Loss: 0.3001\n",
            "Epoch 14/50, Loss: 0.3103\n",
            "Epoch 15/50, Loss: 0.2854\n",
            "Epoch 16/50, Loss: 0.3104\n",
            "Epoch 17/50, Loss: 0.2902\n",
            "Epoch 18/50, Loss: 0.2496\n",
            "Epoch 19/50, Loss: 0.2867\n",
            "Epoch 20/50, Loss: 0.2376\n",
            "Epoch 21/50, Loss: 0.2442\n",
            "Epoch 22/50, Loss: 0.2526\n",
            "Epoch 23/50, Loss: 0.2603\n",
            "Epoch 24/50, Loss: 0.2461\n",
            "Epoch 25/50, Loss: 0.2605\n",
            "Epoch 26/50, Loss: 0.2281\n",
            "Epoch 27/50, Loss: 0.2306\n",
            "Epoch 28/50, Loss: 0.2412\n",
            "Epoch 29/50, Loss: 0.2376\n",
            "Epoch 30/50, Loss: 0.2554\n",
            "Epoch 31/50, Loss: 0.2319\n",
            "Epoch 32/50, Loss: 0.2355\n",
            "Epoch 33/50, Loss: 0.2616\n",
            "Epoch 34/50, Loss: 0.2370\n",
            "Epoch 35/50, Loss: 0.2364\n",
            "Epoch 36/50, Loss: 0.2403\n",
            "Epoch 37/50, Loss: 0.2284\n",
            "Epoch 38/50, Loss: 0.2247\n",
            "Epoch 39/50, Loss: 0.2112\n",
            "Epoch 40/50, Loss: 0.2312\n",
            "Epoch 41/50, Loss: 0.2478\n",
            "Epoch 42/50, Loss: 0.1988\n",
            "Epoch 43/50, Loss: 0.2131\n",
            "Epoch 44/50, Loss: 0.2205\n",
            "Epoch 45/50, Loss: 0.2017\n",
            "Epoch 46/50, Loss: 0.2110\n",
            "Epoch 47/50, Loss: 0.2009\n",
            "Epoch 48/50, Loss: 0.2052\n",
            "Epoch 49/50, Loss: 0.2255\n",
            "Epoch 50/50, Loss: 0.2276\n",
            "Fold 1 Accuracy: 0.8289\n",
            "\n",
            "Fold 2/5\n",
            "Epoch 1/50, Loss: 0.5153\n",
            "Epoch 2/50, Loss: 0.4320\n",
            "Epoch 3/50, Loss: 0.4113\n",
            "Epoch 4/50, Loss: 0.3922\n",
            "Epoch 5/50, Loss: 0.3648\n",
            "Epoch 6/50, Loss: 0.3718\n",
            "Epoch 7/50, Loss: 0.4060\n",
            "Epoch 8/50, Loss: 0.3313\n",
            "Epoch 9/50, Loss: 0.3531\n",
            "Epoch 10/50, Loss: 0.3427\n",
            "Epoch 11/50, Loss: 0.3055\n",
            "Epoch 12/50, Loss: 0.3329\n",
            "Epoch 13/50, Loss: 0.3115\n",
            "Epoch 14/50, Loss: 0.2953\n",
            "Epoch 15/50, Loss: 0.3042\n",
            "Epoch 16/50, Loss: 0.2635\n",
            "Epoch 17/50, Loss: 0.3006\n",
            "Epoch 18/50, Loss: 0.2672\n",
            "Epoch 19/50, Loss: 0.2793\n",
            "Epoch 20/50, Loss: 0.2683\n",
            "Epoch 21/50, Loss: 0.2713\n",
            "Epoch 22/50, Loss: 0.2461\n",
            "Epoch 23/50, Loss: 0.2442\n",
            "Epoch 24/50, Loss: 0.2767\n",
            "Epoch 25/50, Loss: 0.2488\n",
            "Epoch 26/50, Loss: 0.2687\n",
            "Epoch 27/50, Loss: 0.2354\n",
            "Epoch 28/50, Loss: 0.2521\n",
            "Epoch 29/50, Loss: 0.2487\n",
            "Epoch 30/50, Loss: 0.2249\n",
            "Epoch 31/50, Loss: 0.2352\n",
            "Epoch 32/50, Loss: 0.2492\n",
            "Epoch 33/50, Loss: 0.2220\n",
            "Epoch 34/50, Loss: 0.2588\n",
            "Epoch 35/50, Loss: 0.2248\n",
            "Epoch 36/50, Loss: 0.2872\n",
            "Epoch 37/50, Loss: 0.2212\n",
            "Epoch 38/50, Loss: 0.2227\n",
            "Epoch 39/50, Loss: 0.2314\n",
            "Epoch 40/50, Loss: 0.2289\n",
            "Epoch 41/50, Loss: 0.2294\n",
            "Epoch 42/50, Loss: 0.2304\n",
            "Epoch 43/50, Loss: 0.2264\n",
            "Epoch 44/50, Loss: 0.2313\n",
            "Epoch 45/50, Loss: 0.2383\n",
            "Epoch 46/50, Loss: 0.2134\n",
            "Epoch 47/50, Loss: 0.2243\n",
            "Epoch 48/50, Loss: 0.2120\n",
            "Epoch 49/50, Loss: 0.2076\n",
            "Epoch 50/50, Loss: 0.2245\n",
            "Fold 2 Accuracy: 0.8495\n",
            "\n",
            "Fold 3/5\n",
            "Epoch 1/50, Loss: 0.5834\n",
            "Epoch 2/50, Loss: 0.4709\n",
            "Epoch 3/50, Loss: 0.4226\n",
            "Epoch 4/50, Loss: 0.4059\n",
            "Epoch 5/50, Loss: 0.3631\n",
            "Epoch 6/50, Loss: 0.3634\n",
            "Epoch 7/50, Loss: 0.3641\n",
            "Epoch 8/50, Loss: 0.3499\n",
            "Epoch 9/50, Loss: 0.3220\n",
            "Epoch 10/50, Loss: 0.3414\n",
            "Epoch 11/50, Loss: 0.3177\n",
            "Epoch 12/50, Loss: 0.3401\n",
            "Epoch 13/50, Loss: 0.3372\n",
            "Epoch 14/50, Loss: 0.3355\n",
            "Epoch 15/50, Loss: 0.2757\n",
            "Epoch 16/50, Loss: 0.2851\n",
            "Epoch 17/50, Loss: 0.2893\n",
            "Epoch 18/50, Loss: 0.2788\n",
            "Epoch 19/50, Loss: 0.2670\n",
            "Epoch 20/50, Loss: 0.2719\n",
            "Epoch 21/50, Loss: 0.3371\n",
            "Epoch 22/50, Loss: 0.2677\n",
            "Epoch 23/50, Loss: 0.2544\n",
            "Epoch 24/50, Loss: 0.2678\n",
            "Epoch 25/50, Loss: 0.2615\n",
            "Epoch 26/50, Loss: 0.2330\n",
            "Epoch 27/50, Loss: 0.2097\n",
            "Epoch 28/50, Loss: 0.2516\n",
            "Epoch 29/50, Loss: 0.2641\n",
            "Epoch 30/50, Loss: 0.2331\n",
            "Epoch 31/50, Loss: 0.2490\n",
            "Epoch 32/50, Loss: 0.2728\n",
            "Epoch 33/50, Loss: 0.2526\n",
            "Epoch 34/50, Loss: 0.2537\n",
            "Epoch 35/50, Loss: 0.2352\n",
            "Epoch 36/50, Loss: 0.2362\n",
            "Epoch 37/50, Loss: 0.2653\n",
            "Epoch 38/50, Loss: 0.2344\n",
            "Epoch 39/50, Loss: 0.2324\n",
            "Epoch 40/50, Loss: 0.2192\n",
            "Epoch 41/50, Loss: 0.2482\n",
            "Epoch 42/50, Loss: 0.2407\n",
            "Epoch 43/50, Loss: 0.2267\n",
            "Epoch 44/50, Loss: 0.2056\n",
            "Epoch 45/50, Loss: 0.2117\n",
            "Epoch 46/50, Loss: 0.2206\n",
            "Epoch 47/50, Loss: 0.2507\n",
            "Epoch 48/50, Loss: 0.2353\n",
            "Epoch 49/50, Loss: 0.2055\n",
            "Epoch 50/50, Loss: 0.2754\n",
            "Fold 3 Accuracy: 0.6990\n",
            "\n",
            "Fold 4/5\n",
            "Epoch 1/50, Loss: 0.5322\n",
            "Epoch 2/50, Loss: 0.4354\n",
            "Epoch 3/50, Loss: 0.4307\n",
            "Epoch 4/50, Loss: 0.3930\n",
            "Epoch 5/50, Loss: 0.4113\n",
            "Epoch 6/50, Loss: 0.3851\n",
            "Epoch 7/50, Loss: 0.3834\n",
            "Epoch 8/50, Loss: 0.3775\n",
            "Epoch 9/50, Loss: 0.3475\n",
            "Epoch 10/50, Loss: 0.3363\n",
            "Epoch 11/50, Loss: 0.3333\n",
            "Epoch 12/50, Loss: 0.3178\n",
            "Epoch 13/50, Loss: 0.3477\n",
            "Epoch 14/50, Loss: 0.3220\n",
            "Epoch 15/50, Loss: 0.3127\n",
            "Epoch 16/50, Loss: 0.3172\n",
            "Epoch 17/50, Loss: 0.3100\n",
            "Epoch 18/50, Loss: 0.3031\n",
            "Epoch 19/50, Loss: 0.3093\n",
            "Epoch 20/50, Loss: 0.2635\n",
            "Epoch 21/50, Loss: 0.2887\n",
            "Epoch 22/50, Loss: 0.3135\n",
            "Epoch 23/50, Loss: 0.2858\n",
            "Epoch 24/50, Loss: 0.2609\n",
            "Epoch 25/50, Loss: 0.2753\n",
            "Epoch 26/50, Loss: 0.2728\n",
            "Epoch 27/50, Loss: 0.2694\n",
            "Epoch 28/50, Loss: 0.2349\n",
            "Epoch 29/50, Loss: 0.2522\n",
            "Epoch 30/50, Loss: 0.2780\n",
            "Epoch 31/50, Loss: 0.2395\n",
            "Epoch 32/50, Loss: 0.2571\n",
            "Epoch 33/50, Loss: 0.2227\n",
            "Epoch 34/50, Loss: 0.2179\n",
            "Epoch 35/50, Loss: 0.2692\n",
            "Epoch 36/50, Loss: 0.2223\n",
            "Epoch 37/50, Loss: 0.2489\n",
            "Epoch 38/50, Loss: 0.2448\n",
            "Epoch 39/50, Loss: 0.2365\n",
            "Epoch 40/50, Loss: 0.2152\n",
            "Epoch 41/50, Loss: 0.2639\n",
            "Epoch 42/50, Loss: 0.2440\n",
            "Epoch 43/50, Loss: 0.2221\n",
            "Epoch 44/50, Loss: 0.2199\n",
            "Epoch 45/50, Loss: 0.2399\n",
            "Epoch 46/50, Loss: 0.2377\n",
            "Epoch 47/50, Loss: 0.2206\n",
            "Epoch 48/50, Loss: 0.2272\n",
            "Epoch 49/50, Loss: 0.2449\n",
            "Epoch 50/50, Loss: 0.2148\n",
            "Fold 4 Accuracy: 0.8536\n",
            "\n",
            "Fold 5/5\n",
            "Epoch 1/50, Loss: 0.5101\n",
            "Epoch 2/50, Loss: 0.4271\n",
            "Epoch 3/50, Loss: 0.4244\n",
            "Epoch 4/50, Loss: 0.3834\n",
            "Epoch 5/50, Loss: 0.3693\n",
            "Epoch 6/50, Loss: 0.3789\n",
            "Epoch 7/50, Loss: 0.3645\n",
            "Epoch 8/50, Loss: 0.3392\n",
            "Epoch 9/50, Loss: 0.3469\n",
            "Epoch 10/50, Loss: 0.3416\n",
            "Epoch 11/50, Loss: 0.3197\n",
            "Epoch 12/50, Loss: 0.3052\n",
            "Epoch 13/50, Loss: 0.3071\n",
            "Epoch 14/50, Loss: 0.2995\n",
            "Epoch 15/50, Loss: 0.2695\n",
            "Epoch 16/50, Loss: 0.2907\n",
            "Epoch 17/50, Loss: 0.3186\n",
            "Epoch 18/50, Loss: 0.2707\n",
            "Epoch 19/50, Loss: 0.2846\n",
            "Epoch 20/50, Loss: 0.2760\n",
            "Epoch 21/50, Loss: 0.2621\n",
            "Epoch 22/50, Loss: 0.2854\n",
            "Epoch 23/50, Loss: 0.2256\n",
            "Epoch 24/50, Loss: 0.2722\n",
            "Epoch 25/50, Loss: 0.2462\n",
            "Epoch 26/50, Loss: 0.2787\n",
            "Epoch 27/50, Loss: 0.2233\n",
            "Epoch 28/50, Loss: 0.2423\n",
            "Epoch 29/50, Loss: 0.2341\n",
            "Epoch 30/50, Loss: 0.2229\n",
            "Epoch 31/50, Loss: 0.2753\n",
            "Epoch 32/50, Loss: 0.2345\n",
            "Epoch 33/50, Loss: 0.2451\n",
            "Epoch 34/50, Loss: 0.2624\n",
            "Epoch 35/50, Loss: 0.2422\n",
            "Epoch 36/50, Loss: 0.2371\n",
            "Epoch 37/50, Loss: 0.2421\n",
            "Epoch 38/50, Loss: 0.2111\n",
            "Epoch 39/50, Loss: 0.2529\n",
            "Epoch 40/50, Loss: 0.2375\n",
            "Epoch 41/50, Loss: 0.2057\n",
            "Epoch 42/50, Loss: 0.2592\n",
            "Epoch 43/50, Loss: 0.2108\n",
            "Epoch 44/50, Loss: 0.2917\n",
            "Epoch 45/50, Loss: 0.2279\n",
            "Epoch 46/50, Loss: 0.2206\n",
            "Epoch 47/50, Loss: 0.2361\n",
            "Epoch 48/50, Loss: 0.2451\n",
            "Epoch 49/50, Loss: 0.2241\n",
            "Epoch 50/50, Loss: 0.2399\n",
            "Fold 5 Accuracy: 0.7773\n",
            "\n",
            "Average Accuracy across all folds: 0.8016\n",
            "Saved best model weights to /content/drive/My Drive/Disorder/Models/Bintu/best_gat_model.pth\n",
            "Saved true labels to /content/drive/My Drive/Disorder/Models/Bintu/best_true_labels.npy\n",
            "Saved predicted labels to /content/drive/My Drive/Disorder/Models/Bintu/best_predicted_labels.npy\n",
            "Saved confusion matrix plot to /content/drive/My Drive/Disorder/Models/Bintu/confusion.png\n",
            "Cross-validation accuracies: [0.8288659793814434, 0.8494845360824742, 0.6989690721649484, 0.8536082474226804, 0.777319587628866]\n",
            "Best accuracy: 0.8536082474226804\n"
          ]
        }
      ],
      "source": [
        "# Assuming labels are derived from the graphs\n",
        "labels_K = [graph.y.item() for graph in graphs_K]\n",
        "labels_S = [graph.y.item() for graph in graphs_S]\n",
        "labels_B = [graph.y.item() for graph in graphs_B]\n",
        "labels = [labels_K, labels_S, labels_B]\n",
        "save_path_ISO = '/content/drive/My Drive/Disorder/Models/TF_Isoforms'\n",
        "save_path_STARK = '/content/drive/My Drive/Disorder/Models/STARK'\n",
        "save_path_BINTU = '/content/drive/My Drive/Disorder/Models/Bintu'\n",
        "\n",
        "paths = [save_path_ISO, save_path_STARK, save_path_BINTU]\n",
        "graphs = [graphs_K, graphs_S, graphs_B]\n",
        "for i in range(2, 3):\n",
        "# Cross-validation\n",
        "  fold_accuracies, best_accuracy = cross_validate(\n",
        "      graphs=graphs[i],\n",
        "      labels=labels[i],\n",
        "      num_features=num_features,\n",
        "      hidden_dim=hidden_dim,\n",
        "      out_dim=out_dim,\n",
        "      num_classes=num_classes,\n",
        "      class_names=class_names,\n",
        "      k_folds=5,\n",
        "      num_epochs=50,\n",
        "      save_path = paths[i]\n",
        "  )\n",
        "\n",
        "  print(f\"Cross-validation accuracies: {fold_accuracies}\")\n",
        "  print(f\"Best accuracy: {best_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ycdQPTjjH00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "acd6d702-f990-492f-a6a3-4d72146563da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [179, 332]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e667e0315c82>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fold_accuracies, best_accuracy = cross_validate(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mgraphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraphs_S\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-61a95abcece3>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(graphs, labels, num_features, hidden_dim, out_dim, num_classes, class_names, k_folds, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mbest_predicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstratified_kfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nFold {fold + 1}/{k_folds}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \"\"\"\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [179, 332]"
          ]
        }
      ],
      "source": [
        "fold_accuracies, best_accuracy = cross_validate(\n",
        "    graphs=graphs_S,\n",
        "    labels=labels,\n",
        "    num_features=num_features,\n",
        "    hidden_dim=hidden_dim,\n",
        "    out_dim=out_dim,\n",
        "    num_classes=num_classes,\n",
        "    class_names=class_names,\n",
        "    k_folds=5,\n",
        "    num_epochs=100,\n",
        "    save_path = save_path_STARK\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,2):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9mcweAjqFGN",
        "outputId": "60bc3d13-6aa9-40ae-e803-6b77ef035c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLfYz-tDjA0i"
      },
      "source": [
        "### Testing on a different dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx-3oh_TLzbc"
      },
      "outputs": [],
      "source": [
        "def load_best_model(num_features, hidden_dim, out_dim, num_classes, model_path):\n",
        "    # Initialize the model architecture\n",
        "    model = GATWithMasking(num_features, hidden_dim, out_dim, num_classes)\n",
        "\n",
        "    # Load the best model's weights\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    return model\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def predict(\n",
        "    new_graphs, true_labels, num_features, hidden_dim, out_dim, num_classes, class_names, model_path, batch_size=16\n",
        "):\n",
        "    # Load the best model\n",
        "    model = load_best_model(num_features, hidden_dim, out_dim, num_classes, model_path)\n",
        "    model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "    # Create a DataLoader for the new dataset\n",
        "    new_loader = DataLoader(new_graphs, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize lists to store predictions\n",
        "    all_predictions = []\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in new_loader:\n",
        "            data = data.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "            # Run the model to get predictions\n",
        "            out = model(data)\n",
        "            preds = out.argmax(dim=1)  # Get the predicted class\n",
        "\n",
        "            all_predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy on the new dataset\n",
        "    accuracy = accuracy_score(true_labels, all_predictions)\n",
        "    print(f\"Accuracy on the new dataset: {accuracy:.4f}\")\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plot_confusion_matrix(true_labels, all_predictions, class_names)\n",
        "\n",
        "    return all_predictions\n",
        "def get_class_names_from_graphs(graphs):\n",
        "    # Extract unique labels from the graphs\n",
        "    unique_labels = sorted(set([int(graph.y.item()) for graph in graphs]))\n",
        "\n",
        "    # Map each label to a class name (e.g., 0 -> 'Class 0', 1 -> 'Class 1')\n",
        "    class_names = [f'Class {label}' for label in unique_labels]\n",
        "    return class_names\n",
        "def get_true_labels_from_graphs(graphs):\n",
        "    # Extract the 'y' attribute from each graph in the list\n",
        "    true_labels = [int(graph.y.item()) for graph in graphs]\n",
        "    return true_labels\n",
        "def get_class_names_from_graphs(graphs):\n",
        "    # Extract unique labels from the graphs\n",
        "    unique_labels = sorted(set([int(graph.y.item()) for graph in graphs]))\n",
        "\n",
        "    # Map each label to a class name (e.g., 0 -> 'Class 0', 1 -> 'Class 1')\n",
        "    class_names = [f'Class {label}' for label in unique_labels]\n",
        "    return class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elPrJICgMeib"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnDveOyoKtp7"
      },
      "source": [
        "Test the model on the TF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAXSx5bWqqd5",
        "outputId": "a8686dd2-ced0-4528-ef81-a7abbc81bb4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total amount of graphs: 504\n"
          ]
        }
      ],
      "source": [
        "graphs_kaia = '/content/drive/My Drive/Disorder/Input_data/graphs_full_BINTU_STARK_cut.pkl'\n",
        "with open(graphs_kaia, 'rb') as f:\n",
        "    graphs_kaia = pickle.load(f)\n",
        "print(f\"The total amount of graphs: {len(graphs_kaia)}\")\n",
        "for graph in graphs_kaia:\n",
        "    if graph.y.item() == -1:\n",
        "        graph.y = torch.tensor([0])\n",
        "    elif graph.y.item() == 1:\n",
        "        graph.y = torch.tensor([1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "ZCze_-bbLerf",
        "outputId": "6ed70936-70bd-45fb-8010-d99120379aa7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-a8dce11eb43b>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the new dataset: 0.6468\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "true_labels = get_true_labels_from_graphs(graphs_kaia)\n",
        "# Extract class names from the graphs_kaia dataset\n",
        "class_names_kaia = get_class_names_from_graphs(graphs_kaia)\n",
        "# Predict on the new dataset\n",
        "model_path = '/content/drive/My Drive/Disorder/Models/model_test/best_gat_model.pth'\n",
        "predictions = predict(\n",
        "    new_graphs=graphs_kaia,\n",
        "    true_labels=true_labels,\n",
        "    num_features=graphs[0].num_node_features,\n",
        "    hidden_dim=hidden_dim,\n",
        "    out_dim=out_dim,\n",
        "    num_classes=num_classes,\n",
        "    class_names=class_names_kaia,\n",
        "    model_path=model_path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "towgBCAtPn9L",
        "outputId": "60208c8f-1a84-44ee-838e-10d1f41e6996"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graphs[0].num_node_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMhinxU1Prm0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO0ozqy2fbHtQm7qCXCbxTd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}